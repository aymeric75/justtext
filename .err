WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
Using TensorFlow backend.
Fancy Traceback (most recent call last):
  File latplan/main/common.py line 132 function main : task(args)
              parameters = {'test_noise': False, 'test_hard': True, 'train_noise': True, 'train_hard': False, 'dropout_z': False, 'noise': 0.2, 'dropout': 0.2, 'optimizer': 'radam', 'min_temperature': 0.5, 'epoch': 2000, 'gs_annealing_start': 0, 'gs_annealing_end': 1000, 'kl_cycle_start': 2000, 'clipnorm': 0.1, 'batch_size': [400], 'lr': [0.001], 'N': [50, 100, 300], 'zerosuppress': 0.1, 'densify': False, 'max_temperature': [5.0], 'conv_channel': [32], 'conv_channel_increment': [1], 'conv_kernel': [5], 'conv_pooling': [1], 'conv_per_pooling': [1], 'conv_depth': [3], 'fc_width': [100], 'fc_depth': [2], 'A': [6000], 'aae_activation': ['relu'], 'aae_width': [1000], 'aae_depth': [2], 'eff_regularizer': [None], 'beta_d': [1, 10, 100, '...<2 more>'], 'beta_z': [1, 10], 'output': 'GaussianOutput(sigma=0.1)'}
                  params = {'test_noise': False, 'test_hard': True, 'train_noise': True, 'train_hard': False, 'dropout_z': False, 'noise': 0.2, 'dropout': 0.2, 'optimizer': 'radam', 'min_temperature': 0.5, 'epoch': 2000, 'gs_annealing_start': 0, 'gs_annealing_end': 1000, 'kl_cycle_start': 2000, 'clipnorm': 0.1, 'batch_size': [400], 'lr': [0.001], 'N': [50, 100, 300], 'zerosuppress': 0.1, 'densify': False, 'max_temperature': [5.0], 'conv_channel': [32], 'conv_channel_increment': [1], 'conv_kernel': [5], 'conv_pooling': [1], 'conv_per_pooling': [1], 'conv_depth': [3], 'fc_width': [100], 'fc_depth': [2], 'A': [6000], 'aae_activation': ['relu'], 'aae_width': [1000], 'aae_depth': [2], 'eff_regularizer': [None], 'beta_d': [1, 10, 100, '...<2 more>'], 'beta_z': [1, 10], 'output': 'GaussianOutput(sigma=0.1)'}

  File latplan/main/sokoban.py line 42 function sokoban : ae = run(os.path.join("samples",common.sae_path), transitions)
                    args = Namespace(aeclass='CubeSpaceAE_AMA4Conv', comment='kltune2', hash='05-11T07:43:01.194', mode='learn', num_examples=20000, track='sokoban_image-20000-global-global-2-train')
             transitions = '<numpy.ndarray float64  (19999, 2, 28, 28, 3)>'
                  states = '<numpy.ndarray float64  (39998, 28, 28, 3)>'

  File latplan/main/common.py line 278 function run : task()
            path_to_json = 'samples/sokoban_sokoban_image-20000-global-global-2-train_20000_CubeSpaceAE_AMA4Conv_kltune2/logs/05-11T07:43:01.194'
                       f = <_io.TextIOWrapper name='samples/sokoban_sokoban_image-20000-global-global-2-train_20000_CubeSpaceAE_AMA4Conv_kltune2/logs/05-11T07:43:01.194/aux.json' mode='r' encoding='UTF-8'>
              parameters = {'test_noise': False, 'test_hard': True, 'train_noise': True, 'train_hard': False, 'dropout_z': False, 'noise': 0.2, 'dropout': 0.2, 'optimizer': 'radam', 'min_temperature': 0.5, 'epoch': 2000, 'gs_annealing_start': 0, 'gs_annealing_end': 1000, 'kl_cycle_start': 2000, 'clipnorm': 0.1, 'batch_size': 400, 'lr': 0.001, 'N': 300, 'zerosuppress': 0.1, 'densify': False, 'max_temperature': 5.0, 'conv_channel': 32, 'conv_channel_increment': 1, 'conv_kernel': 5, 'conv_pooling': 1, 'conv_per_pooling': 1, 'conv_depth': 3, 'fc_width': 100, 'fc_depth': 2, 'A': 6000, 'aae_activation': 'relu', 'aae_width': 1000, 'aae_depth': 2, 'eff_regularizer': None, 'beta_d': 1000, 'beta_z': 10, 'output': 'GaussianOutput(sigma=0.1)', 'mode': 'learn', 'track': 'sokoban_image-20000-global-global-2-train', 'num_examples': 20000, 'aeclass': 'CubeSpaceAE_AMA4Conv', 'comment': 'kltune2', 'generator': None, 'picsize': [[28, 28, 3]], 'mean': [[[0.858823529411715, 0.8313725490191176, 0.6901960784
                   extra = None
                    path = 'samples/sokoban_sokoban_image-20000-global-global-2-train_20000_CubeSpaceAE_AMA4Conv_kltune2'
                    test = '<numpy.ndarray float64  (1000, 2, 28, 28, 3)>'
                   train = '<numpy.ndarray float64  (17999, 2, 28, 28, 3)>'
             transitions = '<numpy.ndarray float64  (19999, 2, 28, 28, 3)>'
                     val = '<numpy.ndarray float64  (1000, 2, 28, 28, 3)>'

  File latplan/util/util.py line 2 function <lambda> : return lambda *args,**kwargs: fn(*args1,*args,**{**kwargs1,**kwargs})
                    args = ()
                  kwargs = {}
                   args1 = ((<class 'latplan.model.ConvolutionalConcreteDetNormalizedLogitAddBidirectionalTransitionAEPlus'>, 0), ('samples/sokoban_sokoban_image-20000-global-global-2-train_20000_CubeSpaceAE_AMA4Conv_kltune2', 1), ('<numpy.ndarray float64  (17999, 2, 28, 28, 3)>', 2), ('...<5 more>', None))
                 kwargs1 = {}

  File latplan/util/tuning.py line 140 function nn_task : net.train(train_in,
                    path = 'samples/sokoban_sokoban_image-20000-global-global-2-train_20000_CubeSpaceAE_AMA4Conv_kltune2'
                train_in = '<numpy.ndarray float64  (17999, 2, 28, 28, 3)>'
               train_out = '<numpy.ndarray float64  (17999, 2, 28, 28, 3)>'
                  val_in = '<numpy.ndarray float64  (1000, 2, 28, 28, 3)>'
                 val_out = '<numpy.ndarray float64  (1000, 2, 28, 28, 3)>'
              parameters = {'test_noise': False, 'test_hard': True, 'train_noise': True, 'train_hard': False, 'dropout_z': False, 'noise': 0.2, 'dropout': 0.2, 'optimizer': 'radam', 'min_temperature': 0.5, 'epoch': 2000, 'gs_annealing_start': 0, 'gs_annealing_end': 1000, 'kl_cycle_start': 2000, 'clipnorm': 0.1, 'batch_size': 400, 'lr': 0.001, 'N': 300, 'zerosuppress': 0.1, 'densify': False, 'max_temperature': 5.0, 'conv_channel': 32, 'conv_channel_increment': 1, 'conv_kernel': 5, 'conv_pooling': 1, 'conv_per_pooling': 1, 'conv_depth': 3, 'fc_width': 100, 'fc_depth': 2, 'A': 6000, 'aae_activation': 'relu', 'aae_width': 1000, 'aae_depth': 2, 'eff_regularizer': None, 'beta_d': 1000, 'beta_z': 10, 'output': 'GaussianOutput(sigma=0.1)', 'mode': 'learn', 'track': 'sokoban_image-20000-global-global-2-train', 'num_examples': 20000, 'aeclass': 'CubeSpaceAE_AMA4Conv', 'comment': 'kltune2', 'generator': None, 'picsize': [[28, 28, 3]], 'mean': [[[0.858823529411715, 0.8313725490191176, 0.6901960784
                  resume = False
                     net = <latplan.model.ConvolutionalConcreteDetNormalizedLogitAddBidirectionalTransitionAEPlus object at 0x7fc7d4c7cfd0>

  File latplan/network.py line 678 function train : gradients = tape.gradient(loss_value, net.trainable_weights)
                        val_data = ['<numpy.ndarray float64  (1000, 2, 28, 28, 3)>']
                     val_data_to = ['<numpy.ndarray float64  (1000, 2, 28, 28, 3)>']
                          resume = False
                          kwargs = {'test_noise': False, 'test_hard': True, 'train_noise': True, 'train_hard': False, 'dropout_z': False, 'noise': 0.2, 'dropout': 0.2, 'optimizer': 'radam', 'min_temperature': 0.5, 'epoch': 2000, 'gs_annealing_start': 0, 'gs_annealing_end': 1000, 'kl_cycle_start': 2000, 'clipnorm': 0.1, 'batch_size': 400, 'lr': 0.001, 'N': 300, 'zerosuppress': 0.1, 'densify': False, 'max_temperature': 5.0, 'conv_channel': 32, 'conv_channel_increment': 1, 'conv_kernel': 5, 'conv_pooling': 1, 'conv_per_pooling': 1, 'conv_depth': 3, 'fc_width': 100, 'fc_depth': 2, 'A': 6000, 'aae_activation': 'relu', 'aae_width': 1000, 'aae_depth': 2, 'eff_regularizer': None, 'beta_d': 1000, 'beta_z': 10, 'output': 'GaussianOutput(sigma=0.1)', 'mode': 'learn', 'track': 'sokoban_image-20000-global-global-2-train', 'num_examples': 20000, 'aeclass': 'CubeSpaceAE_AMA4Conv', 'comment': 'kltune2', 'generator': None, 'picsize': [[28, 28, 3]], 'mean': [[[0.858823529411715, 0.8313725490191176, 0.69
                     input_shape = ((2, 0), (28, 1), (28, 2), ('...<1 more>', None))
                           epoch = 0
                     start_epoch = 0
                     index_array = '<numpy.ndarray int64    (17999,)>'
                           clist = <keras.callbacks.CallbackList object at 0x7fc923411e50>
                      some_count = 0
                      is_correct = 0
                            logs = {}
                          states = '<numpy.ndarray float64  (39998, 28, 28, 3)>'
                          resset = False
                         loss_fn = <tensorflow.python.keras.losses.CategoricalCrossentropy object at 0x7fc92342aa90>
                   indices_cache = ['<numpy.ndarray int64    (400,)>', '<numpy.ndarray int64    (400,)>', '<numpy.ndarray int64    (400,)>', '...<41 more>']
                train_data_cache = [['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], '...<41 more>']
             train_data_to_cache = [['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>'], '...<41 more>']
             train_subdata_cache = ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>']
          train_subdata_to_cache = ['<numpy.ndarray float64  (400, 2, 28, 28, 3)>']
                             net = <keras.engine.training.Model object at 0x7fc923918d30>
       train_subdata_batch_cache = '<numpy.ndarray float64  (400, 2, 28, 28, 3)>'
    train_subdata_to_batch_cache = '<numpy.ndarray float64  (400, 2, 28, 28, 3)>'
                            tape = <tensorflow.python.eager.backprop.GradientTape object at 0x7fc9233b7fd0>
                           preds = <tf.Tensor 'model_1/dmerge_5/concat:0' shape=(?, 2, 28, 28, 3) dtype=float32>
                      loss_value = <tf.Tensor 'model_1/lambda_1/Abs:0' shape=() dtype=float32>
                      batch_size = 400
                        clipnorm = 0.1
                              lr = 0.001
                       optimizer = 'radam'
                   plot_val_data = '<numpy.ndarray float64  (1, 2, 28, 28, 3)>'
                            self = <latplan.model.ConvolutionalConcreteDetNormalizedLogitAddBidirectionalTransitionAEPlus object at 0x7fc7d4c7cfd0>
                      train_data = ['<numpy.ndarray float64  (17999, 2, 28, 28, 3)>']
                   train_data_to = ['<numpy.ndarray float64  (17999, 2, 28, 28, 3)>']

  File ../../../usr/local/lib/python3.8/dist-packages/tensorflow_core/python/eager/backprop.py line 1009 function gradient : flat_grad = imperative_grad.imperative_grad(
                     self = <tensorflow.python.eager.backprop.GradientTape object at 0x7fc9233b7fd0>
                   target = <tf.Tensor 'model_1/lambda_1/Abs:0' shape=() dtype=float32>
                  sources = [<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, '...<33 more>']
         output_gradients = None
    unconnected_gradients = <UnconnectedGradients.NONE: 'none'>
             flat_targets = [<tf.Tensor 'model_1/lambda_1/Abs:0' shape=() dtype=float32>]
                        t = <tf.Variable 'conv2d_transpose_2/bias:0' shape=(3,) dtype=float32_ref>
             flat_sources = [<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, '...<33 more>']
         flat_sources_raw = [<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, '...<33 more>']

  File ../../../usr/local/lib/python3.8/dist-packages/tensorflow_core/python/eager/imperative_grad.py line 70 function imperative_grad : return pywrap_tensorflow.TFE_Py_TapeGradient(
                     tape = <tensorflow.python.eager.tape.Tape object at 0x7fc923386640>
                   target = [<tf.Tensor 'model_1/lambda_1/Abs:0' shape=() dtype=float32>]
                  sources = [<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, '...<33 more>']
         output_gradients = None
              sources_raw = [<tf.Variable 'batch_normalization_2/gamma:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'batch_normalization_2/beta:0' shape=(3,) dtype=float32_ref>, <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 3, 32) dtype=float32_ref>, '...<33 more>']
    unconnected_gradients = <UnconnectedGradients.NONE: 'none'>


AttributeError: 'RefVariable' object has no attribute '_id'

